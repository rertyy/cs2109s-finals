{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def generate_synthetic(X, labels, n_neighbors=3):\n",
    "    X = X.copy()\n",
    "    print(X.shape)\n",
    "    X_where_y0 = X[labels == 0]  # majority class\n",
    "    X_where_y1 = X[labels == 1]\n",
    "    X_where_y2 = X[labels == 2]\n",
    "    y0_num = X_where_y0.shape[0]\n",
    "    y1_num = X_where_y1.shape[0]\n",
    "    y2_num = X_where_y2.shape[0]\n",
    "\n",
    "    X_w_y1_reshaped = X_where_y1.reshape(X_where_y1.shape[0], -1)\n",
    "    X_w_y2_reshaped = X_where_y2.reshape(X_where_y2.shape[0], -1)\n",
    "\n",
    "    y1_upsample = y0_num - y1_num\n",
    "    y2_upsample = y0_num - y2_num\n",
    "\n",
    "    X_w_y1_synthetic = smote(X_w_y1_reshaped, y1_upsample, n_neighbors)\n",
    "    X_w_y2_synthetic = smote(X_w_y2_reshaped, y2_upsample, n_neighbors)\n",
    "\n",
    "    X_w_y1_synthetic = X_w_y1_synthetic.reshape(-1, *X_where_y1.shape[1:])\n",
    "    X_w_y2_synthetic = X_w_y2_synthetic.reshape(-1, *X_where_y2.shape[1:])\n",
    "\n",
    "    X_oversampled = np.vstack([X, X_w_y1_synthetic, X_w_y2_synthetic])\n",
    "    y_oversampled = np.hstack([\n",
    "        labels,\n",
    "        np.ones(X_w_y1_synthetic.shape[0]),\n",
    "        np.full(X_w_y2_synthetic.shape[0], 2)\n",
    "    ])\n",
    "\n",
    "    return X_oversampled, y_oversampled\n",
    "\n",
    "\n",
    "def smote(X, num_oversamples, n_neighbors=5):\n",
    "    n_samples, n_features = X.shape\n",
    "    synthetic_samples = np.zeros((num_oversamples, n_features))\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn.fit(X)\n",
    "\n",
    "    indices = np.random.randint(0, n_samples, size=num_oversamples)\n",
    "    samples = X[indices]\n",
    "\n",
    "    nnres = nn.kneighbors(samples, return_distance=False)\n",
    "\n",
    "    nn_indices = nnres[np.arange(num_oversamples), np.random.randint(0, n_neighbors, size=num_oversamples)]\n",
    "    nn_samples = X[nn_indices]\n",
    "\n",
    "    diffs = nn_samples - samples\n",
    "    synthetic_samples = samples + diffs * np.random.random(size=(num_oversamples, 1))\n",
    "\n",
    "    return synthetic_samples.reshape(num_oversamples, *X.shape[1:])\n",
    "\n",
    "\n",
    "def drop_nan_y(X, y):\n",
    "    nan_indices = np.argwhere(np.isnan(y)).squeeze()\n",
    "    mask = np.ones(y.shape, bool)\n",
    "    mask[nan_indices] = False\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def clean_x_data(X):\n",
    "    X[np.isnan(X)] = np.nanmedian(X)\n",
    "    X[X < 0] = 0\n",
    "    X[X > 255] = 255\n",
    "    # lower = np.percentile(X, 25) * 1.15\n",
    "    # upper = np.percentile(X, 75) * 1.5\n",
    "    # X[X < lower] = lower\n",
    "    # X[X > upper] = upper\n",
    "    return X\n",
    "\n",
    "\n",
    "class CustomNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, classes=3, drop_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(drop_prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            # nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"\n",
    "    This class represents an AI model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size=20,\n",
    "                 epochs=15,\n",
    "                #  epochs=25,\n",
    "                 criterion=nn.CrossEntropyLoss(),\n",
    "                 num_components=256,\n",
    "                 scaler=MinMaxScaler(),\n",
    "                #  learning_rate=1e-3,\n",
    "                 learning_rate=0.00236972,\n",
    "                #  drop_prob=0.3\n",
    "                 drop_prob=0.475464\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Constructor for Model class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        self : object\n",
    "            The instance of the object passed by Python.\n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own initialization code.\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # self.device = torch.device(\"cpu\")\n",
    "        self.optimizer = None\n",
    "        self.model = None\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.num_components = num_components\n",
    "        self.pca = PCA(n_components=num_components, svd_solver='full')\n",
    "        self.scaler = scaler\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using the input data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Training data.\n",
    "        y : ndarray of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of the trained model.\n",
    "        \"\"\"\n",
    "        # TODO: Add your training code.\n",
    "\n",
    "        self.model = CustomNeuralNetwork(input_size=self.num_components)\n",
    "        # self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.01)\n",
    "\n",
    "        print('start')\n",
    "\n",
    "        X, y = drop_nan_y(X, y)\n",
    "\n",
    "        X = clean_x_data(X)\n",
    "\n",
    "        # print(\"pre-synthetic\")\n",
    "        X, y = generate_synthetic(X, y, 5)\n",
    "        # print(y.min())\n",
    "        print(\"y_train shape:\", y[y==0].shape, y[y==1].shape, y[y==2].shape)\n",
    "\n",
    "        # X, X_test, y, y_test = train_test_split(X, y, test_size=100)\n",
    "        # print(y.min())\n",
    "\n",
    "        # Flatten and normalize the data\n",
    "        flattened_data = X.reshape(X.shape[0], -1)\n",
    "\n",
    "        normalized_data = self.scaler.fit_transform(flattened_data)\n",
    "        # print(\"pre-pca\")\n",
    "        # print(y.min())\n",
    "        pca_result = self.pca.fit_transform(normalized_data)\n",
    "        reconstructed = self.pca.inverse_transform(pca_result)\n",
    "        original_pca = reconstructed.reshape(-1, *X.shape[1:])\n",
    "\n",
    "        pca_result_tensor = torch.tensor(original_pca, dtype=torch.float32)  #.to(self.device)\n",
    "        labels_tensor = torch.tensor(y, dtype=torch.long)  # .to(self.device)\n",
    "\n",
    "        # print(y.min())\n",
    "        # dataset = CustomTensorDataset(tensors=(pca_result_tensor, labels_tensor), transform=get_augmentations())\n",
    "        dataset = TensorDataset(pca_result_tensor, labels_tensor)\n",
    "        train_loader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        # print(\"pre-epoch\")\n",
    "\n",
    "        epoch_losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0\n",
    "            # print(f\"Epoch {epoch+1}\")\n",
    "            for inputs, labels in train_loader:\n",
    "                # print(inputs, labels)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            # self.scheduler.step()\n",
    "            epoch_losses.append(epoch_loss / len(train_loader))\n",
    "            print(f\"Epoch {epoch + 1} loss: {epoch_losses[-1]}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to make predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray of shape (n_samples,)\n",
    "        Predicted target values per element in X.\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own prediction code.\n",
    "        X = clean_x_data(X)\n",
    "\n",
    "        X = torch.from_numpy(X).float()\n",
    "        # X.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        flattened_data = X.reshape(X.shape[0], -1)\n",
    "        normalized_data = self.scaler.transform(flattened_data)\n",
    "        pca_result = self.pca.transform(normalized_data)\n",
    "        reconstructed = self.pca.inverse_transform(pca_result)\n",
    "        original_pca = reconstructed.reshape(-1, *X.shape[1:])\n",
    "\n",
    "        original_pca = torch.tensor(original_pca, dtype=torch.float32)  #.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(original_pca)\n",
    "        return outputs.detach().numpy().argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281a5b44f486ecb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T10:03:20.328679800Z",
     "start_time": "2023-11-26T10:03:20.314693100Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8544187e503b070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T10:03:23.285748Z",
     "start_time": "2023-11-26T10:03:21.534172800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']\n",
    "\n",
    "\n",
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Filter test data that contains no labels\n",
    "# In Coursemology, the test data is guaranteed to have labels\n",
    "nan_indices = np.argwhere(np.isnan(y_test)).squeeze()\n",
    "mask = np.ones(y_test.shape, bool)\n",
    "mask[nan_indices] = False\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Train and predict\n",
    "model = Model()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model predition\n",
    "# Learn more: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "print(\"F1 Score (macro): {0:.2f}\".format(f1_score(y_test, y_pred, average='macro'))) # You may encounter errors, you are expected to figure out what's the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defd3a53f285b047",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2157,) (2157,) (2157,)\n",
      "Epoch 1 loss: 1.0990238318472734\n",
      "Epoch 2 loss: 1.0950885650552349\n",
      "Epoch 3 loss: 1.0814983870512174\n",
      "Epoch 4 loss: 0.7582738130916784\n",
      "Epoch 5 loss: 0.3357265753740514\n",
      "Epoch 6 loss: 0.2396235428750515\n",
      "Epoch 7 loss: 0.19213291446183933\n",
      "Epoch 8 loss: 0.15956705413689767\n",
      "Epoch 9 loss: 0.15169156112213744\n",
      "Epoch 10 loss: 0.13177599698121165\n",
      "Epoch 11 loss: 0.11851991501199886\n",
      "Epoch 12 loss: 0.10206889174016262\n",
      "Epoch 13 loss: 0.09473008220371457\n",
      "Epoch 14 loss: 0.08411983162219303\n",
      "Epoch 15 loss: 0.07091324621765518\n",
      "y_test values: (235,) (26,) (1,)\n",
      "predictions: (222,) (37,) (3,)\n",
      "f1: 0.6693237470042721\n",
      "Fold: 2\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2146,) (2146,) (2146,)\n",
      "Epoch 1 loss: 1.0986282181295548\n",
      "Epoch 2 loss: 1.0960089841984815\n",
      "Epoch 3 loss: 1.0880899085021167\n",
      "Epoch 4 loss: 0.9005818359600091\n",
      "Epoch 5 loss: 0.44104579040167496\n",
      "Epoch 6 loss: 0.2762847077448546\n",
      "Epoch 7 loss: 0.22291672455366723\n",
      "Epoch 8 loss: 0.18914339401012992\n",
      "Epoch 9 loss: 0.16388579608976656\n",
      "Epoch 10 loss: 0.14648965292072258\n",
      "Epoch 11 loss: 0.12970236445320135\n",
      "Epoch 12 loss: 0.12987890030309465\n",
      "Epoch 13 loss: 0.1053514850227544\n",
      "Epoch 14 loss: 0.09067129624012557\n",
      "Epoch 15 loss: 0.08393718058573117\n",
      "y_test values: (246,) (16,) (0,)\n",
      "predictions: (231,) (31,) (0,)\n",
      "f1: 0.6844640706543557\n",
      "Fold: 3\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2151,) (2151,) (2151,)\n",
      "Epoch 1 loss: 1.098462702320087\n",
      "Epoch 2 loss: 1.095713121234079\n",
      "Epoch 3 loss: 1.0839088236215313\n",
      "Epoch 4 loss: 0.8075539754824742\n",
      "Epoch 5 loss: 0.3948021412541623\n",
      "Epoch 6 loss: 0.238159365017809\n",
      "Epoch 7 loss: 0.2052012643439482\n",
      "Epoch 8 loss: 0.1756216591114507\n",
      "Epoch 9 loss: 0.15888753692812688\n",
      "Epoch 10 loss: 0.15616954942651948\n",
      "Epoch 11 loss: 0.13494724633846858\n",
      "Epoch 12 loss: 0.126792199589635\n",
      "Epoch 13 loss: 0.1072148509012195\n",
      "Epoch 14 loss: 0.09819351260091867\n",
      "Epoch 15 loss: 0.08877025951340149\n",
      "y_test values: (241,) (19,) (2,)\n",
      "predictions: (224,) (35,) (3,)\n",
      "f1: 0.6491437674233372\n",
      "Fold: 4\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2153,) (2153,) (2153,)\n",
      "Epoch 1 loss: 1.0984912774880236\n",
      "Epoch 2 loss: 1.096264819611706\n",
      "Epoch 3 loss: 1.0893140791370404\n",
      "Epoch 4 loss: 0.9075276505651858\n",
      "Epoch 5 loss: 0.4423188364634942\n",
      "Epoch 6 loss: 0.26705688737540423\n",
      "Epoch 7 loss: 0.22676343330104284\n",
      "Epoch 8 loss: 0.19236489450530186\n",
      "Epoch 9 loss: 0.1738612081613334\n",
      "Epoch 10 loss: 0.16306060593252303\n",
      "Epoch 11 loss: 0.1432474235580202\n",
      "Epoch 12 loss: 0.1293481402791137\n",
      "Epoch 13 loss: 0.1221924814260089\n",
      "Epoch 14 loss: 0.10999448877548793\n",
      "Epoch 15 loss: 0.10171580987177997\n",
      "y_test values: (239,) (19,) (4,)\n",
      "predictions: (231,) (28,) (3,)\n",
      "f1: 0.6413373860182371\n",
      "Fold: 5\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2159,) (2159,) (2159,)\n",
      "Epoch 1 loss: 1.0977827737360826\n",
      "Epoch 2 loss: 1.0889231948940843\n",
      "Epoch 3 loss: 0.8527438619438513\n",
      "Epoch 4 loss: 0.41192551840234687\n",
      "Epoch 5 loss: 0.2556126719156717\n",
      "Epoch 6 loss: 0.215588590848823\n",
      "Epoch 7 loss: 0.192433002623327\n",
      "Epoch 8 loss: 0.16540237473047995\n",
      "Epoch 9 loss: 0.15023615679209246\n",
      "Epoch 10 loss: 0.1410096607107761\n",
      "Epoch 11 loss: 0.12529337478019756\n",
      "Epoch 12 loss: 0.1073447016303508\n",
      "Epoch 13 loss: 0.09697252160001454\n",
      "Epoch 14 loss: 0.08641835085452637\n",
      "Epoch 15 loss: 0.07742015397417601\n",
      "y_test values: (233,) (25,) (4,)\n",
      "predictions: (228,) (30,) (4,)\n",
      "f1: 0.787776901334385\n",
      "Fold: 6\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2158,) (2158,) (2158,)\n",
      "Epoch 1 loss: 1.0984079664872017\n",
      "Epoch 2 loss: 1.0960847529364222\n",
      "Epoch 3 loss: 1.0874036315046711\n",
      "Epoch 4 loss: 0.8722293579284056\n",
      "Epoch 5 loss: 0.36809696969978606\n",
      "Epoch 6 loss: 0.2479496957205328\n",
      "Epoch 7 loss: 0.20448787998477067\n",
      "Epoch 8 loss: 0.18267302013312778\n",
      "Epoch 9 loss: 0.1666417916615804\n",
      "Epoch 10 loss: 0.15072242244445708\n",
      "Epoch 11 loss: 0.13903537430271598\n",
      "Epoch 12 loss: 0.12214043232278875\n",
      "Epoch 13 loss: 0.10950029984312017\n",
      "Epoch 14 loss: 0.10044107503936063\n",
      "Epoch 15 loss: 0.08225216218097894\n",
      "y_test values: (234,) (24,) (4,)\n",
      "predictions: (221,) (37,) (4,)\n",
      "f1: 0.7602744250285234\n",
      "Fold: 7\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2154,) (2154,) (2154,)\n",
      "Epoch 1 loss: 1.098872047883493\n",
      "Epoch 2 loss: 1.095926512170721\n",
      "Epoch 3 loss: 1.0880623194906447\n",
      "Epoch 4 loss: 0.9139220445060435\n",
      "Epoch 5 loss: 0.3741334229477762\n",
      "Epoch 6 loss: 0.24517520709124244\n",
      "Epoch 7 loss: 0.1972617897561487\n",
      "Epoch 8 loss: 0.1778621688876071\n",
      "Epoch 9 loss: 0.15082669158661624\n",
      "Epoch 10 loss: 0.13548755894392084\n",
      "Epoch 11 loss: 0.12521094397245044\n",
      "Epoch 12 loss: 0.10630904077437281\n",
      "Epoch 13 loss: 0.0994683642351402\n",
      "Epoch 14 loss: 0.08376531653899562\n",
      "Epoch 15 loss: 0.07677764279637982\n",
      "y_test values: (238,) (21,) (3,)\n",
      "predictions: (224,) (34,) (4,)\n",
      "f1: 0.7956709956709956\n",
      "Fold: 8\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2151,) (2151,) (2151,)\n",
      "Epoch 1 loss: 1.0991443794209153\n",
      "Epoch 2 loss: 1.0973788477688013\n",
      "Epoch 3 loss: 1.0941623718745936\n",
      "Epoch 4 loss: 1.0732771143455624\n",
      "Epoch 5 loss: 0.6986492006771335\n",
      "Epoch 6 loss: 0.3658872201992631\n",
      "Epoch 7 loss: 0.2455976862264307\n",
      "Epoch 8 loss: 0.21011807106942768\n",
      "Epoch 9 loss: 0.18558572907427517\n",
      "Epoch 10 loss: 0.16255384636033707\n",
      "Epoch 11 loss: 0.1503641180659503\n",
      "Epoch 12 loss: 0.1320482205957082\n",
      "Epoch 13 loss: 0.123714643328713\n",
      "Epoch 14 loss: 0.11135910127323478\n",
      "Epoch 15 loss: 0.09821142482314686\n",
      "y_test values: (241,) (19,) (2,)\n",
      "predictions: (222,) (36,) (4,)\n",
      "f1: 0.7464973711194013\n",
      "Fold: 9\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2143,) (2143,) (2143,)\n",
      "Epoch 1 loss: 1.099321683001074\n",
      "Epoch 2 loss: 1.098078808058863\n",
      "Epoch 3 loss: 1.0969372210295305\n",
      "Epoch 4 loss: 1.0927987935380166\n",
      "Epoch 5 loss: 1.057331466711826\n",
      "Epoch 6 loss: 0.592070606184302\n",
      "Epoch 7 loss: 0.30963020870080277\n",
      "Epoch 8 loss: 0.2287291926765664\n",
      "Epoch 9 loss: 0.2013921991152608\n",
      "Epoch 10 loss: 0.18376252911869229\n",
      "Epoch 11 loss: 0.15500624554798656\n",
      "Epoch 12 loss: 0.14562737029219358\n",
      "Epoch 13 loss: 0.12966580347082815\n",
      "Epoch 14 loss: 0.1170727459754309\n",
      "Epoch 15 loss: 0.1047932929156915\n",
      "y_test values: (249,) (10,) (3,)\n",
      "predictions: (222,) (35,) (5,)\n",
      "f1: 0.6650979004482189\n",
      "Fold: 10\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "y_train shape: (2156,) (2156,) (2156,)\n",
      "Epoch 1 loss: 1.0988699591454165\n",
      "Epoch 2 loss: 1.0961313597214075\n",
      "Epoch 3 loss: 1.0878825537216517\n",
      "Epoch 4 loss: 0.8939632853424108\n",
      "Epoch 5 loss: 0.3764079478741796\n",
      "Epoch 6 loss: 0.2510661784398519\n",
      "Epoch 7 loss: 0.2054101104537646\n",
      "Epoch 8 loss: 0.17565014469724746\n",
      "Epoch 9 loss: 0.1570894951690678\n",
      "Epoch 10 loss: 0.14223703574159263\n",
      "Epoch 11 loss: 0.1334376610085414\n",
      "Epoch 12 loss: 0.11458249684469199\n",
      "Epoch 13 loss: 0.10458514050086155\n",
      "Epoch 14 loss: 0.08959738791195883\n",
      "Epoch 15 loss: 0.08232851524946544\n",
      "y_test values: (236,) (24,) (2,)\n",
      "predictions: (234,) (26,) (2,)\n",
      "f1: 0.6991489361702129\n",
      "F1: [0.6693237470042721, 0.6844640706543557, 0.6491437674233372, 0.6413373860182371, 0.787776901334385, 0.7602744250285234, 0.7956709956709956, 0.7464973711194013, 0.6650979004482189, 0.6991489361702129]\n",
      "Mean: 0.7098735500871939\n",
      "Std: 0.05486966636781901\n",
      "Max: 0.7956709956709956\n",
      "Min: 0.6413373860182371\n",
      "peak memory: 846.65 MiB, increment: 242.71 MiB\n",
      "CPU times: total: 33min 34s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# N fold cross validation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']\n",
    "\n",
    "\n",
    "nan_indices = np.argwhere(np.isnan(y)).squeeze()\n",
    "mask = np.ones(y.shape, bool)\n",
    "mask[nan_indices] = False\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "model = Model()\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=2109)\n",
    "\n",
    "f1_scores = []\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    i += 1\n",
    "    print(\"Fold:\", i)\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"y_test values:\", y_test[y_test==0].shape, y_test[y_test==1].shape, y_test[y_test==2].shape)\n",
    "    print(\"predictions:\", predictions[predictions==0].shape, predictions[predictions==1].shape, predictions[predictions==2].shape)\n",
    "\n",
    "    score = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "    f1_scores.append(score)\n",
    "    print(\"f1:\", score)\n",
    "\n",
    "print(\"F1:\", f1_scores)\n",
    "print(\"Mean:\", np.mean(f1_scores))\n",
    "print(\"Std:\", np.std(f1_scores))\n",
    "print(\"Max:\", np.max(f1_scores))\n",
    "print(\"Min:\", np.min(f1_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a6ed329cd7b2c",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 19:10:14,628\tINFO tune.py:586 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-26 19:23:01</td></tr>\n",
       "<tr><td>Running for: </td><td>00:12:46.95        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.2/13.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 16.0/16 CPUs, 1.0/1 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  drop_prob</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_test_model_5fc37_00003</td><td>RUNNING   </td><td>127.0.0.1:23148</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">   0.340535</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.000226005</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_test_model_5fc37_00004</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">   0.294349</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.000274962</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_test_model_5fc37_00005</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">   0.170752</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0545508  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_test_model_5fc37_00006</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.395796</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.000116568</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_test_model_5fc37_00007</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">   0.114746</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.0094335  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_test_model_5fc37_00008</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.256277</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00244211 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_test_model_5fc37_00009</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.134492</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.0196498  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_test_model_5fc37_00000</td><td>TERMINATED</td><td>127.0.0.1:22724</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">   0.221055</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0115636  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         63.5446</td><td style=\"text-align: right;\">0.711292</td></tr>\n",
       "<tr><td>train_test_model_5fc37_00001</td><td>TERMINATED</td><td>127.0.0.1:19652</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.301445</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.00280555 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        447.375 </td><td style=\"text-align: right;\">0.666811</td></tr>\n",
       "<tr><td>train_test_model_5fc37_00002</td><td>TERMINATED</td><td>127.0.0.1:15988</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">   0.148605</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00468248 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         50.7499</td><td style=\"text-align: right;\">0.714469</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_test_model pid=22724)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 1 loss: 0.8083955540603869\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 2 loss: 0.21223365865972404\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 3 loss: 0.15344384711702388\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 4 loss: 0.12023675890689661\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 5 loss: 0.09583282619287577\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 6 loss: 0.0927519511887154\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 7 loss: 0.10599371169658023\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 8 loss: 0.079200748344294\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 9 loss: 0.07458547793734042\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 10 loss: 0.05807995404571232\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 1 loss: 0.9515420264180969\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 2 loss: 0.23775345391296476\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 3 loss: 0.16502959038201376\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 4 loss: 0.13549120021796152\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 5 loss: 0.12367849269326181\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 6 loss: 0.10921259355305635\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 7 loss: 0.07631704131165884\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 8 loss: 0.0950028517131499\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 9 loss: 0.07622564900086845\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 10 loss: 0.08148489109484247\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 1 loss: 0.8951246826472014\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 2 loss: 0.23423320798559158\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 3 loss: 0.15425022451244955\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 4 loss: 0.1424991236314263\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 5 loss: 0.10604022667576299\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 6 loss: 0.10028006628469592\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 7 loss: 0.07722269515139936\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 8 loss: 0.060132568785395475\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 9 loss: 0.051948598017282965\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m Epoch 10 loss: 0.05463724612245129\n",
      "\u001b[36m(train_test_model pid=22724)\u001b[0m fit shape: (873, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_test_model_5fc37_00000</td><td style=\"text-align: right;\">0.711292</td></tr>\n",
       "<tr><td>train_test_model_5fc37_00001</td><td style=\"text-align: right;\">0.666811</td></tr>\n",
       "<tr><td>train_test_model_5fc37_00002</td><td style=\"text-align: right;\">0.714469</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_test_model pid=22724)\u001b[0m F1: 0.7112922614380324\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 1 loss: 1.0986712819807758\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 2 loss: 1.097779239856356\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 3 loss: 1.095982320081149\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 4 loss: 1.0907785447306653\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 5 loss: 1.024331357963847\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 6 loss: 0.5251586282030676\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 7 loss: 0.2796232228735423\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 8 loss: 0.21416369349506387\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 9 loss: 0.18102786341427027\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 10 loss: 0.16798598236593715\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 11 loss: 0.1469304893838234\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 12 loss: 0.1307968634346894\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 13 loss: 0.11368095681565926\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 14 loss: 0.10850088775575284\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 15 loss: 0.09358017937245458\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 16 loss: 0.07800401716311443\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 17 loss: 0.06535671613685384\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 18 loss: 0.06021340557033992\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 19 loss: 0.056002229397548405\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 20 loss: 0.0501642155599166\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 21 loss: 0.042991855083211204\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 22 loss: 0.032006345917055326\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 23 loss: 0.02923094526926419\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 24 loss: 0.030537419331489957\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 25 loss: 0.031062170404494504\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 26 loss: 0.027447977846950154\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 27 loss: 0.02459763251274005\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 28 loss: 0.015301822640747604\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 29 loss: 0.012885686449578063\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 30 loss: 0.013227346643063537\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 1 loss: 1.0985208599507308\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 2 loss: 1.0963079874255077\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 3 loss: 1.0895306122403186\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 4 loss: 0.9917611993160569\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 5 loss: 0.5124306901663291\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 6 loss: 0.3171833307177079\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 7 loss: 0.23517226340139613\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 8 loss: 0.20269239118651433\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 9 loss: 0.18258101410162048\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 10 loss: 0.15138105010347708\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 11 loss: 0.1326330778298571\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 12 loss: 0.1176402805678296\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 13 loss: 0.10275486492387512\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 14 loss: 0.08750932117798875\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 15 loss: 0.07983853520841158\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 16 loss: 0.07025062327298626\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 17 loss: 0.06699150127354822\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 18 loss: 0.05088908622381786\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 19 loss: 0.05504099369937351\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 20 loss: 0.06204257396288498\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 21 loss: 0.03792162862764828\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 22 loss: 0.03335793332114596\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 23 loss: 0.032486493826673575\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 24 loss: 0.026191654971931835\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 25 loss: 0.022441536092743308\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 26 loss: 0.02383691986752263\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 27 loss: 0.020787772210901837\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 28 loss: 0.030513330475361665\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 29 loss: 0.014781666504003463\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 30 loss: 0.01656998301738337\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 1 loss: 1.0983537967006365\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 2 loss: 1.0941861455639204\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 3 loss: 1.0736943726738295\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 4 loss: 0.7330088590582212\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 5 loss: 0.4611447553538407\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 6 loss: 0.2841697781657179\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 7 loss: 0.22565176552161575\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 8 loss: 0.18947770377465833\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 9 loss: 0.16713884761556982\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 10 loss: 0.1507936483559509\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 11 loss: 0.1391964559016439\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 12 loss: 0.12259255902220806\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 13 loss: 0.11371820668379466\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 14 loss: 0.09024100686753324\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 15 loss: 0.08080607165660088\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 16 loss: 0.07405310369795189\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 17 loss: 0.05874900833005085\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 18 loss: 0.055930292067932895\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 19 loss: 0.044249630507207864\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 20 loss: 0.0361702410436313\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 21 loss: 0.03896728900435846\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 22 loss: 0.029399676495813765\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 23 loss: 0.025672079352564953\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 24 loss: 0.020779109019773992\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 25 loss: 0.018190623854267566\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 26 loss: 0.02004430261949892\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 27 loss: 0.022057621591860272\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 28 loss: 0.017022941977605417\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 29 loss: 0.010772662393234593\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m Epoch 30 loss: 0.012397224224484187\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=19652)\u001b[0m F1: 0.6668108337027233\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 1 loss: 1.0992286760614525\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 2 loss: 1.0974245634138213\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 3 loss: 1.0943023269961338\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 4 loss: 1.0773496205762307\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 5 loss: 0.7125467558084808\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 6 loss: 0.2898072524933341\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 7 loss: 0.2163296481420905\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 8 loss: 0.1858970111941699\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 9 loss: 0.1773431617882311\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 10 loss: 0.14584196346192996\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 1 loss: 1.0986149670942775\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 2 loss: 1.0969940094078112\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 3 loss: 1.0924935948173955\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 4 loss: 1.0533939333831739\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 5 loss: 0.6348580553096795\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 6 loss: 0.35333897918462753\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 7 loss: 0.25434312664862696\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 8 loss: 0.20630111161080547\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 9 loss: 0.18666070805124516\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 10 loss: 0.15741888541470533\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 1 loss: 1.0991764165461064\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 2 loss: 1.0972207009792327\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 3 loss: 1.093920563161373\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 4 loss: 1.0689171940088271\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 5 loss: 0.6905937022529542\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 6 loss: 0.33779907738789916\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 7 loss: 0.2399571912130341\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 8 loss: 0.1934385957894847\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 9 loss: 0.17326204932760447\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m Epoch 10 loss: 0.1419229579565581\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=15988)\u001b[0m F1: 0.7144691067035073\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 1 loss: 1.0993712423253357\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 2 loss: 1.0984417944528255\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 3 loss: 1.0979674784968998\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 4 loss: 1.0976918752757345\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 5 loss: 1.0972893440871812\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 6 loss: 1.096918761482872\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 7 loss: 1.0965463501783823\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 8 loss: 1.0960532075636615\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 9 loss: 1.0955270499114673\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 10 loss: 1.0948994384761668\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 11 loss: 1.094228994054913\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 12 loss: 1.0933374262944298\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 13 loss: 1.092167937903978\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 14 loss: 1.0906304088865573\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 15 loss: 1.08892996157848\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 16 loss: 1.0863900261301223\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 17 loss: 1.0829011971030493\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 18 loss: 1.0777602002828448\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 19 loss: 1.0697145956680487\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 20 loss: 1.055878279367423\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 1 loss: 1.0986763466806972\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 2 loss: 1.0982450041450371\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 3 loss: 1.097927482689128\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 4 loss: 1.0976080188230306\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 5 loss: 1.097225014402085\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 6 loss: 1.096828289142176\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 7 loss: 1.0964389353239237\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 8 loss: 1.0958835162034555\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 9 loss: 1.0952315761261628\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 10 loss: 1.094441925277229\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 11 loss: 1.0934499679994183\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 12 loss: 1.0919811510238326\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 13 loss: 1.0900959026913684\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 14 loss: 1.0872563952658356\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 15 loss: 1.0831709742045201\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 16 loss: 1.0764514408191712\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 17 loss: 1.0654651299745095\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 18 loss: 1.042511722495576\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 19 loss: 0.9928590833139019\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 20 loss: 0.8841471261337024\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 1 loss: 1.1000417147399488\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 2 loss: 1.098714517651122\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 3 loss: 1.098207586493522\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 4 loss: 1.0978457126338697\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 5 loss: 1.0975147356320025\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 6 loss: 1.0973163123917231\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 7 loss: 1.0970733989504533\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 8 loss: 1.0967754187812886\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 9 loss: 1.0963863721720113\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 10 loss: 1.09597428606547\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 11 loss: 1.095531148801019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 19:23:01,658\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 12 loss: 1.0950476483661595\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 13 loss: 1.094313529438664\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 14 loss: 1.0932117033602051\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 15 loss: 1.0920265636762647\n",
      "\u001b[36m(train_test_model pid=23148)\u001b[0m Epoch 16 loss: 1.0903776789507935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 19:23:11,778\tINFO tune.py:1047 -- Total run time: 777.15 seconds (766.94 seconds for the tuning loop).\n",
      "2023-11-26 19:23:11,780\tWARNING tune.py:1062 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2023-11-26 19:23:11,799\tWARNING experiment_analysis.py:185 -- Failed to fetch metrics for 6 trial(s):\n",
      "- train_test_model_5fc37_00004: FileNotFoundError('Could not fetch metrics for train_test_model_5fc37_00004: both result.json and progress.csv were not found at C:/Users/Ian/ray_results/train_test_model_2023-11-26_19-10-14/train_test_model_5fc37_00004_4_batch_size=30,drop_prob=0.2943,epochs=30,lr=0.0003_2023-11-26_19-10-15')\n",
      "- train_test_model_5fc37_00005: FileNotFoundError('Could not fetch metrics for train_test_model_5fc37_00005: both result.json and progress.csv were not found at C:/Users/Ian/ray_results/train_test_model_2023-11-26_19-10-14/train_test_model_5fc37_00005_5_batch_size=10,drop_prob=0.1708,epochs=10,lr=0.0546_2023-11-26_19-10-15')\n",
      "- train_test_model_5fc37_00006: FileNotFoundError('Could not fetch metrics for train_test_model_5fc37_00006: both result.json and progress.csv were not found at C:/Users/Ian/ray_results/train_test_model_2023-11-26_19-10-14/train_test_model_5fc37_00006_6_batch_size=20,drop_prob=0.3958,epochs=20,lr=0.0001_2023-11-26_19-10-15')\n",
      "- train_test_model_5fc37_00007: FileNotFoundError('Could not fetch metrics for train_test_model_5fc37_00007: both result.json and progress.csv were not found at C:/Users/Ian/ray_results/train_test_model_2023-11-26_19-10-14/train_test_model_5fc37_00007_7_batch_size=10,drop_prob=0.1147,epochs=30,lr=0.0094_2023-11-26_19-10-15')\n",
      "- train_test_model_5fc37_00008: FileNotFoundError('Could not fetch metrics for train_test_model_5fc37_00008: both result.json and progress.csv were not found at C:/Users/Ian/ray_results/train_test_model_2023-11-26_19-10-14/train_test_model_5fc37_00008_8_batch_size=20,drop_prob=0.2563,epochs=10,lr=0.0024_2023-11-26_19-10-15')\n",
      "- train_test_model_5fc37_00009: FileNotFoundError('Could not fetch metrics for train_test_model_5fc37_00009: both result.json and progress.csv were not found at C:/Users/Ian/ray_results/train_test_model_2023-11-26_19-10-14/train_test_model_5fc37_00009_9_batch_size=20,drop_prob=0.1345,epochs=30,lr=0.0196_2023-11-26_19-10-15')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If set, `mode` has to be one of [min, max]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ian\\OneDrive - National University of Singapore\\Y2S1\\CS2109S\\Finals\\final\\tuning.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m# \"criterion\": tune.choice([nn.CrossEntropyLoss, nn.MSELoss]),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m# \"scaler\": tune.choice([MinMaxScaler(), StandardScaler()]),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         \u001b[39m# \"class_weights\": tune.grid_search(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         \u001b[39m#         )\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m analysis \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     train_test_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m best_trial \u001b[39m=\u001b[39m analysis\u001b[39m.\u001b[39;49mget_best_trial(\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mavg\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mlast\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mprint\u001b[39m(best_trial\u001b[39m.\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\Ian\\miniconda3\\envs\\cs2109s-2310-final\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:535\u001b[0m, in \u001b[0;36mExperimentAnalysis.get_best_trial\u001b[1;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials[\u001b[39m0\u001b[39m]\n\u001b[0;32m    534\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_metric(metric)\n\u001b[1;32m--> 535\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_mode(mode)\n\u001b[0;32m    537\u001b[0m \u001b[39mif\u001b[39;00m scope \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast-5-avg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast-10-avg\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    538\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    539\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExperimentAnalysis: attempting to get best trial for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmetric \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for scope \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not in [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         )\n\u001b[0;32m    546\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ian\\miniconda3\\envs\\cs2109s-2310-final\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:650\u001b[0m, in \u001b[0;36mExperimentAnalysis._validate_mode\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    646\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo `mode` has been passed and  `default_mode` has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    647\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot been set. Please specify the `mode` parameter.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    648\u001b[0m     )\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39mand\u001b[39;00m mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 650\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf set, `mode` has to be one of [min, max]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    651\u001b[0m \u001b[39mreturn\u001b[39;00m mode \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_mode\n",
      "\u001b[1;31mValueError\u001b[0m: If set, `mode` has to be one of [min, max]"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from ray import train\n",
    "from ray.air import session\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def drop_nan_y(X, y):\n",
    "    nan_indices = np.argwhere(np.isnan(y)).squeeze()\n",
    "    mask = np.ones(y.shape, bool)\n",
    "    mask[nan_indices] = False\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    return X, y\n",
    "\n",
    "# Load data\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']\n",
    "\n",
    "\n",
    "X, y = drop_nan_y(X, y)\n",
    "\n",
    "def train_test_model(config):\n",
    "    model = Model(\n",
    "        batch_size=config[\"batch_size\"],\n",
    "                    epochs=config[\"epochs\"], \n",
    "                    # criterion=config[\"criterion\"],\n",
    "                    # scaler=config[\"scaler\"],\n",
    "                    learning_rate=config[\"lr\"])\n",
    "                    # class_weights=config[\"class_weights\"],\n",
    "                    \n",
    "    \n",
    "    kf = KFold(n_splits=3)\n",
    "    f1_scores = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, predictions, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    print(\"F1:\", avg_f1)\n",
    "    train.report({\"score\": avg_f1})\n",
    "    \n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"drop_prob\": tune.uniform(0.1, 0.5),\n",
    "    \"batch_size\": tune.choice([10, 20, 30]),\n",
    "    \"epochs\": tune.choice([10, 20, 30]),\n",
    "}\n",
    "    # \"criterion\": tune.choice([nn.CrossEntropyLoss, nn.MSELoss]),\n",
    "    # \"scaler\": tune.choice([MinMaxScaler(), StandardScaler()]),\n",
    "        # \"class_weights\": tune.grid_search(\n",
    "        #     map(lambda x: torch.tensor(x, dtype=torch.float32),\n",
    "        #         [[1.0, 3.0, 5.0],\n",
    "        #           [1.0, 5.0, 10.0],\n",
    "        #             [1.0, 10.0, 35.0],\n",
    "        #             [1.0, 10.0, 50.0],\n",
    "        #               [1.0, 100.0, 500.0]]\n",
    "        #         )\n",
    "        #     )\n",
    "\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_test_model,\n",
    "    config=config,\n",
    "    num_samples=10, \n",
    "    resources_per_trial={\"cpu\": 16, \"gpu\": 1} \n",
    "\n",
    ")\n",
    "best_trial = analysis.get_best_trial(\"score\",\"avg\",\"last\")\n",
    "print(best_trial.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6df97cb7432b9",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "2023-11-26 13:26:34,995\tINFO tune.py:1047 -- Total run time: 583.14 seconds (583.05 seconds for the tuning loop).\n",
    "{'lr': 0.0003826645125269827, 'drop_prob': 0.23535222860200122, 'batch_size': 20, 'epochs': 10, 'scaler': StandardScaler()}\n",
    "\n",
    "\n",
    "Trial name\t                    status\tloc\t       batch_size\tdrop_prob\tepochs\tlr\titer\ttotal time (s)\tscore\n",
    "\n",
    "train_test_model_6416e_00008\tTERMINATED\t127.0.0.1:22940\t20\t0.211087\t30\t0.0119396\t1\t137.953\t0.734706\n",
    "\n",
    "train_test_model_6416e_00008\tTERMINATED\t127.0.0.1:22940\t20\t0.211087\t30\t0.0119396\t1\t137.953\t0.734706\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
