{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# def get_augmentations():\n",
    "#     return transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "#                                transforms.RandomVerticalFlip(),\n",
    "#                                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "#                                ])\n",
    "\n",
    "\n",
    "### https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/16\n",
    "# class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "#     def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "#         super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "#         self.gamma = gamma\n",
    "#         self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "\n",
    "#         ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return focal_loss\n",
    "\n",
    "# class CustomTensorDataset(Dataset):\n",
    "#     \"\"\"TensorDataset with support of transforms.\n",
    "#     Copied directly from https://stackoverflow.com/questions/55588201/pytorch-transforms-on-tensordataset\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, tensors, transform=None):\n",
    "#         assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "#         self.tensors = tensors\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         x = self.tensors[0][index]\n",
    "\n",
    "#         if self.transform:\n",
    "#             x = self.transform(x)\n",
    "\n",
    "#         y = self.tensors[1][index]\n",
    "\n",
    "#         return x, y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.tensors[0].size(0)\n",
    "\n",
    "\n",
    "def generate_synthetic(X, labels, n_neighbors=3):\n",
    "    X = X.copy()\n",
    "    print(X.shape)\n",
    "    X_where_y0 = X[labels == 0]  # majority class\n",
    "    X_where_y1 = X[labels == 1]\n",
    "    X_where_y2 = X[labels == 2]\n",
    "    y0_num = X_where_y0.shape[0]\n",
    "    y1_num = X_where_y1.shape[0]\n",
    "    y2_num = X_where_y2.shape[0]\n",
    "\n",
    "    X_w_y1_reshaped = X_where_y1.reshape(X_where_y1.shape[0], -1)\n",
    "    X_w_y2_reshaped = X_where_y2.reshape(X_where_y2.shape[0], -1)\n",
    "\n",
    "    y1_upsample = y0_num - y1_num\n",
    "    y2_upsample = y0_num - y2_num\n",
    "\n",
    "    X_w_y1_synthetic = smote(X_w_y1_reshaped, y1_upsample, n_neighbors)\n",
    "    X_w_y2_synthetic = smote(X_w_y2_reshaped, y2_upsample, n_neighbors)\n",
    "\n",
    "    X_w_y1_synthetic = X_w_y1_synthetic.reshape(-1, *X_where_y1.shape[1:])\n",
    "    X_w_y2_synthetic = X_w_y2_synthetic.reshape(-1, *X_where_y2.shape[1:])\n",
    "\n",
    "    X_oversampled = np.vstack([X, X_w_y1_synthetic, X_w_y2_synthetic])\n",
    "    y_oversampled = np.hstack([\n",
    "        labels,\n",
    "        np.ones(X_w_y1_synthetic.shape[0]),\n",
    "        np.full(X_w_y2_synthetic.shape[0], 2)\n",
    "    ])\n",
    "\n",
    "    return X_oversampled, y_oversampled\n",
    "\n",
    "\n",
    "def smote(X, num_oversamples, n_neighbors=5):\n",
    "    n_samples, n_features = X.shape\n",
    "    synthetic_samples = np.zeros((num_oversamples, n_features))\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn.fit(X)\n",
    "\n",
    "    indices = np.random.randint(0, n_samples, size=num_oversamples)\n",
    "    samples = X[indices]\n",
    "\n",
    "    nnres = nn.kneighbors(samples, return_distance=False)\n",
    "\n",
    "    nn_indices = nnres[np.arange(num_oversamples), np.random.randint(0, n_neighbors, size=num_oversamples)]\n",
    "    nn_samples = X[nn_indices]\n",
    "\n",
    "    diffs = nn_samples - samples\n",
    "    synthetic_samples = samples + diffs * np.random.random(size=(num_oversamples, 1))\n",
    "\n",
    "    return synthetic_samples.reshape(num_oversamples, *X.shape[1:])\n",
    "\n",
    "\n",
    "def drop_nan_y(X, y):\n",
    "    nan_indices = np.argwhere(np.isnan(y)).squeeze()\n",
    "    mask = np.ones(y.shape, bool)\n",
    "    mask[nan_indices] = False\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def clean_x_data(X):\n",
    "    X[np.isnan(X)] = np.nanmedian(X)\n",
    "    X[X < 0] = 0\n",
    "    X[X > 255] = 255\n",
    "    # lower = np.percentile(X, 25) * 1.15\n",
    "    # upper = np.percentile(X, 75) * 1.5\n",
    "    # X[X < lower] = lower\n",
    "    # X[X > upper] = upper\n",
    "    return X\n",
    "\n",
    "\n",
    "class CustomNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, classes=3, drop_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(drop_prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            # nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"\n",
    "    This class represents an AI model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size=10,\n",
    "                 epochs=15,  # epochs seem to get worse after about 10 at num_components=256\n",
    "                 # learning_rate=1e-3,\n",
    "                 criterion=nn.CrossEntropyLoss(),\n",
    "                 num_components=256,\n",
    "                 scaler=MinMaxScaler(),\n",
    "                 learning_rate=1e-3,\n",
    "                 drop_prob=0.3\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Constructor for Model class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        self : object\n",
    "            The instance of the object passed by Python.\n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own initialization code.\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # self.device = torch.device(\"cpu\")\n",
    "        self.optimizer = None\n",
    "        self.model = None\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.num_components = num_components\n",
    "        self.pca = PCA(n_components=num_components, svd_solver='full')\n",
    "        self.scaler = scaler\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using the input data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Training data.\n",
    "        y : ndarray of shape (n_samples,)\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of the trained model.\n",
    "        \"\"\"\n",
    "        # TODO: Add your training code.\n",
    "\n",
    "        self.model = CustomNeuralNetwork(input_size=self.num_components)\n",
    "        # self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.01)\n",
    "\n",
    "        print('start')\n",
    "\n",
    "        X, y = drop_nan_y(X, y)\n",
    "\n",
    "        X = clean_x_data(X)\n",
    "\n",
    "        # print(\"pre-synthetic\")\n",
    "        X, y = generate_synthetic(X, y, 5)\n",
    "        # print(y.min())\n",
    "\n",
    "        # X, X_test, y, y_test = train_test_split(X, y, test_size=100)\n",
    "        # print(y.min())\n",
    "\n",
    "        # Flatten and normalize the data\n",
    "        flattened_data = X.reshape(X.shape[0], -1)\n",
    "\n",
    "        normalized_data = self.scaler.fit_transform(flattened_data)\n",
    "        # print(\"pre-pca\")\n",
    "        # print(y.min())\n",
    "        pca_result = self.pca.fit_transform(normalized_data)\n",
    "        reconstructed = self.pca.inverse_transform(pca_result)\n",
    "        original_pca = reconstructed.reshape(-1, *X.shape[1:])\n",
    "\n",
    "        pca_result_tensor = torch.tensor(original_pca, dtype=torch.float32)  #.to(self.device)\n",
    "        labels_tensor = torch.tensor(y, dtype=torch.long)  # .to(self.device)\n",
    "\n",
    "        # print(y.min())\n",
    "        # dataset = CustomTensorDataset(tensors=(pca_result_tensor, labels_tensor), transform=get_augmentations())\n",
    "        dataset = TensorDataset(pca_result_tensor, labels_tensor)\n",
    "        train_loader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        # print(\"pre-epoch\")\n",
    "\n",
    "        epoch_losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0\n",
    "            # print(f\"Epoch {epoch+1}\")\n",
    "            for inputs, labels in train_loader:\n",
    "                # print(inputs, labels)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            # self.scheduler.step()\n",
    "            epoch_losses.append(epoch_loss / len(train_loader))\n",
    "            print(f\"Epoch {epoch + 1} loss: {epoch_losses[-1]}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to make predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray of shape (n_samples,)\n",
    "        Predicted target values per element in X.\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own prediction code.\n",
    "        X = clean_x_data(X)\n",
    "\n",
    "        X = torch.from_numpy(X).float()\n",
    "        # X.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        flattened_data = X.reshape(X.shape[0], -1)\n",
    "        normalized_data = self.scaler.transform(flattened_data)\n",
    "        pca_result = self.pca.transform(normalized_data)\n",
    "        reconstructed = self.pca.inverse_transform(pca_result)\n",
    "        original_pca = reconstructed.reshape(-1, *X.shape[1:])\n",
    "\n",
    "        print(\"fit shape:\", pca_result.shape)\n",
    "\n",
    "        original_pca = torch.tensor(original_pca, dtype=torch.float32)  #.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(original_pca)\n",
    "        return outputs.detach().numpy().argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281a5b44f486ecb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T10:03:20.328679800Z",
     "start_time": "2023-11-26T10:03:20.314693100Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8544187e503b070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T10:03:23.285748Z",
     "start_time": "2023-11-26T10:03:21.534172800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "(2365, 3, 16, 16)\n",
      "Epoch 1 loss: 1.0977361263042256\n",
      "Epoch 2 loss: 1.0951246382464213\n",
      "Epoch 3 loss: 1.0819580337547998\n",
      "Epoch 4 loss: 0.8250489204062561\n",
      "Epoch 5 loss: 0.4284857962355363\n",
      "Epoch 6 loss: 0.2689931994042081\n",
      "Epoch 7 loss: 0.21845076338804026\n",
      "Epoch 8 loss: 0.1893357831259277\n",
      "Epoch 9 loss: 0.16522660299666353\n",
      "Epoch 10 loss: 0.15085351954997334\n",
      "Epoch 11 loss: 0.1367433666761884\n",
      "Epoch 12 loss: 0.12620407238946665\n",
      "Epoch 13 loss: 0.11528050025113191\n",
      "Epoch 14 loss: 0.10496610685696442\n",
      "Epoch 15 loss: 0.09547137864145638\n",
      "fit shape: (255, 256)\n",
      "F1 Score (macro): 0.61\n",
      "peak memory: 579.54 MiB, increment: 302.58 MiB\n",
      "CPU times: total: 3min 47s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']\n",
    "\n",
    "\n",
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Filter test data that contains no labels\n",
    "# In Coursemology, the test data is guaranteed to have labels\n",
    "nan_indices = np.argwhere(np.isnan(y_test)).squeeze()\n",
    "mask = np.ones(y_test.shape, bool)\n",
    "mask[nan_indices] = False\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Train and predict\n",
    "model = Model()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model predition\n",
    "# Learn more: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "print(\"F1 Score (macro): {0:.2f}\".format(f1_score(y_test, y_pred, average='macro'))) # You may encounter errors, you are expected to figure out what's the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defd3a53f285b047",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.0995490808545807\n",
      "Epoch 2 loss: 1.0978720335312833\n",
      "Epoch 3 loss: 1.0966030760311787\n",
      "Epoch 4 loss: 1.092843108707004\n",
      "Epoch 5 loss: 1.0670485305197446\n",
      "Epoch 6 loss: 0.6924570200987804\n",
      "Epoch 7 loss: 0.3857140674451251\n",
      "Epoch 8 loss: 0.24781747490604533\n",
      "Epoch 9 loss: 0.20338727083534325\n",
      "Epoch 10 loss: 0.18147107235437696\n",
      "Epoch 11 loss: 0.17185845521758714\n",
      "Epoch 12 loss: 0.149684341340527\n",
      "Epoch 13 loss: 0.13230731951491045\n",
      "Epoch 14 loss: 0.12230195306790533\n",
      "Epoch 15 loss: 0.11333795733958983\n",
      "fit shape: (262, 256)\n",
      "f1: 0.6892196368993457\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.097461345217983\n",
      "Epoch 2 loss: 1.0922668781709968\n",
      "Epoch 3 loss: 1.0522634283356045\n",
      "Epoch 4 loss: 0.5895020859258145\n",
      "Epoch 5 loss: 0.3058424540882155\n",
      "Epoch 6 loss: 0.23340197128492482\n",
      "Epoch 7 loss: 0.20105528944426487\n",
      "Epoch 8 loss: 0.1716224492429206\n",
      "Epoch 9 loss: 0.15388220978571068\n",
      "Epoch 10 loss: 0.14025268759014467\n",
      "Epoch 11 loss: 0.12825634108128905\n",
      "Epoch 12 loss: 0.1148892650507269\n",
      "Epoch 13 loss: 0.10984667069900503\n",
      "Epoch 14 loss: 0.09531613725695978\n",
      "Epoch 15 loss: 0.08759598836941956\n",
      "fit shape: (262, 256)\n",
      "f1: 0.733739837398374\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.0988067497409904\n",
      "Epoch 2 loss: 1.0962962722261624\n",
      "Epoch 3 loss: 1.0919440541843142\n",
      "Epoch 4 loss: 1.0644968963075347\n",
      "Epoch 5 loss: 0.6493464486310172\n",
      "Epoch 6 loss: 0.3121536112918112\n",
      "Epoch 7 loss: 0.22933544454830856\n",
      "Epoch 8 loss: 0.20223962580323818\n",
      "Epoch 9 loss: 0.1874549970846773\n",
      "Epoch 10 loss: 0.16376343309077732\n",
      "Epoch 11 loss: 0.15739227293582558\n",
      "Epoch 12 loss: 0.14453452506287157\n",
      "Epoch 13 loss: 0.13328840060667033\n",
      "Epoch 14 loss: 0.12685016624884674\n",
      "Epoch 15 loss: 0.11119276187173595\n",
      "fit shape: (262, 256)\n",
      "f1: 0.6579823418729194\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.099431605900035\n",
      "Epoch 2 loss: 1.0977720155066382\n",
      "Epoch 3 loss: 1.0959812631548005\n",
      "Epoch 4 loss: 1.090005712058891\n",
      "Epoch 5 loss: 1.0088778111403203\n",
      "Epoch 6 loss: 0.5056698329216186\n",
      "Epoch 7 loss: 0.29649677355384496\n",
      "Epoch 8 loss: 0.22415840914674773\n",
      "Epoch 9 loss: 0.2008135922919186\n",
      "Epoch 10 loss: 0.18425374406450443\n",
      "Epoch 11 loss: 0.16667576352907085\n",
      "Epoch 12 loss: 0.15394660458617465\n",
      "Epoch 13 loss: 0.14423199523753563\n",
      "Epoch 14 loss: 0.12562097707653747\n",
      "Epoch 15 loss: 0.12188627143843163\n",
      "fit shape: (262, 256)\n",
      "f1: 0.7317255943865386\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.0990267037241548\n",
      "Epoch 2 loss: 1.0976361433664958\n",
      "Epoch 3 loss: 1.0960582457942727\n",
      "Epoch 4 loss: 1.0913353573392939\n",
      "Epoch 5 loss: 1.0496403851810796\n",
      "Epoch 6 loss: 0.6348879302817362\n",
      "Epoch 7 loss: 0.3704996226200213\n",
      "Epoch 8 loss: 0.25305393815937416\n",
      "Epoch 9 loss: 0.21493903398341327\n",
      "Epoch 10 loss: 0.1905424089162369\n",
      "Epoch 11 loss: 0.1765452439603568\n",
      "Epoch 12 loss: 0.162919371883977\n",
      "Epoch 13 loss: 0.1498079504422487\n",
      "Epoch 14 loss: 0.13532882988493153\n",
      "Epoch 15 loss: 0.12235774544001568\n",
      "fit shape: (262, 256)\n",
      "f1: 0.7780493359963558\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.0985698379852153\n",
      "Epoch 2 loss: 1.097187829606327\n",
      "Epoch 3 loss: 1.0941474590404534\n",
      "Epoch 4 loss: 1.0760785390933354\n",
      "Epoch 5 loss: 0.7491602568576733\n",
      "Epoch 6 loss: 0.37255822276742556\n",
      "Epoch 7 loss: 0.2632333832522739\n",
      "Epoch 8 loss: 0.21620508824348633\n",
      "Epoch 9 loss: 0.19235285678102323\n",
      "Epoch 10 loss: 0.17086211084905598\n",
      "Epoch 11 loss: 0.1589112410984393\n",
      "Epoch 12 loss: 0.14334305150098064\n",
      "Epoch 13 loss: 0.13217127438559897\n",
      "Epoch 14 loss: 0.12006842146015347\n",
      "Epoch 15 loss: 0.1101969809632139\n",
      "fit shape: (262, 256)\n",
      "f1: 0.8037606837606838\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.0984797112908578\n",
      "Epoch 2 loss: 1.0968868664280156\n",
      "Epoch 3 loss: 1.0933042276403082\n",
      "Epoch 4 loss: 1.072985403043962\n",
      "Epoch 5 loss: 0.736220510955756\n",
      "Epoch 6 loss: 0.35665728622209714\n",
      "Epoch 7 loss: 0.24702662121867286\n",
      "Epoch 8 loss: 0.1995723038959321\n",
      "Epoch 9 loss: 0.18509414521876544\n",
      "Epoch 10 loss: 0.1670439995420806\n",
      "Epoch 11 loss: 0.15207409592693702\n",
      "Epoch 12 loss: 0.1466267668466491\n",
      "Epoch 13 loss: 0.12532979972916763\n",
      "Epoch 14 loss: 0.11607358333585609\n",
      "Epoch 15 loss: 0.10827477699306892\n",
      "fit shape: (262, 256)\n",
      "f1: 0.7852083990329025\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.0989790630783458\n",
      "Epoch 2 loss: 1.098199047355829\n",
      "Epoch 3 loss: 1.09687191081859\n",
      "Epoch 4 loss: 1.0937692331086741\n",
      "Epoch 5 loss: 1.076783845852772\n",
      "Epoch 6 loss: 0.78477383851313\n",
      "Epoch 7 loss: 0.4368653095935705\n",
      "Epoch 8 loss: 0.28229066701288746\n",
      "Epoch 9 loss: 0.22483901997261188\n",
      "Epoch 10 loss: 0.20427792598767316\n",
      "Epoch 11 loss: 0.1850578536152632\n",
      "Epoch 12 loss: 0.16856554274132976\n",
      "Epoch 13 loss: 0.14645796777224945\n",
      "Epoch 14 loss: 0.1333988021166084\n",
      "Epoch 15 loss: 0.12155086632303305\n",
      "fit shape: (262, 256)\n",
      "f1: 0.7564554890831928\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.098743157661165\n",
      "Epoch 2 loss: 1.0970422993551703\n",
      "Epoch 3 loss: 1.0933904699737882\n",
      "Epoch 4 loss: 1.072064475545987\n",
      "Epoch 5 loss: 0.7286806828219264\n",
      "Epoch 6 loss: 0.384239566710837\n",
      "Epoch 7 loss: 0.265864187314191\n",
      "Epoch 8 loss: 0.2239600235153088\n",
      "Epoch 9 loss: 0.19414533700208828\n",
      "Epoch 10 loss: 0.17709131332905167\n",
      "Epoch 11 loss: 0.1560059498103327\n",
      "Epoch 12 loss: 0.14358945935023124\n",
      "Epoch 13 loss: 0.13132700115995566\n",
      "Epoch 14 loss: 0.11097728802705209\n",
      "Epoch 15 loss: 0.10271793150547226\n",
      "fit shape: (262, 256)\n",
      "f1: 0.667029511369134\n",
      "start\n",
      "(2358, 3, 16, 16)\n",
      "Epoch 1 loss: 1.098413526551248\n",
      "Epoch 2 loss: 1.0962609867039936\n",
      "Epoch 3 loss: 1.0895519389251285\n",
      "Epoch 4 loss: 0.9921832012798539\n",
      "Epoch 5 loss: 0.5285566781504998\n",
      "Epoch 6 loss: 0.3144998149845571\n",
      "Epoch 7 loss: 0.23650250520407462\n",
      "Epoch 8 loss: 0.20382489839502518\n",
      "Epoch 9 loss: 0.1776958218008464\n",
      "Epoch 10 loss: 0.16558912644159895\n",
      "Epoch 11 loss: 0.14758825402021686\n",
      "Epoch 12 loss: 0.13483407676984288\n",
      "Epoch 13 loss: 0.1270235632684793\n",
      "Epoch 14 loss: 0.1147160478417763\n",
      "Epoch 15 loss: 0.10507969002108417\n",
      "fit shape: (262, 256)\n",
      "f1: 0.7031579891647364\n",
      "F1: [0.6892196368993457, 0.733739837398374, 0.6579823418729194, 0.7317255943865386, 0.7780493359963558, 0.8037606837606838, 0.7852083990329025, 0.7564554890831928, 0.667029511369134, 0.7031579891647364]\n",
      "Mean: 0.7306328818964183\n",
      "Std: 0.04800578416250182\n",
      "Max: 0.8037606837606838\n",
      "Min: 0.6579823418729194\n",
      "peak memory: 654.11 MiB, increment: 241.33 MiB\n",
      "CPU times: total: 38min 4s\n",
      "Wall time: 11min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# N fold cross validation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']\n",
    "\n",
    "\n",
    "nan_indices = np.argwhere(np.isnan(y)).squeeze()\n",
    "mask = np.ones(y.shape, bool)\n",
    "mask[nan_indices] = False\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "model = Model()\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=2109)\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    model.fit(X=X[train_index], y=y[train_index])\n",
    "\n",
    "    predictions = model.predict(X[test_index])\n",
    "\n",
    "    score = f1_score(y[test_index], predictions, average='macro')\n",
    "\n",
    "    f1_scores.append(score)\n",
    "    print(\"f1:\", score)\n",
    "\n",
    "print(\"F1:\", f1_scores)\n",
    "print(\"Mean:\", np.mean(f1_scores))\n",
    "print(\"Std:\", np.std(f1_scores))\n",
    "print(\"Max:\", np.max(f1_scores))\n",
    "print(\"Min:\", np.min(f1_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913a6ed329cd7b2c",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 18:27:24,955\tINFO tune.py:586 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-26 18:50:08</td></tr>\n",
       "<tr><td>Running for: </td><td>00:22:43.98        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.5/13.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 16.0/16 CPUs, 1.0/1 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  drop_prob</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_test_model_6416e_00000</td><td>TERMINATED</td><td>127.0.0.1:25400</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.475464</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.00236972 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        143.559 </td><td style=\"text-align: right;\">0.714657</td></tr>\n",
       "<tr><td>train_test_model_6416e_00001</td><td>TERMINATED</td><td>127.0.0.1:14488</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.140988</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.000697144</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        137.29  </td><td style=\"text-align: right;\">0.633559</td></tr>\n",
       "<tr><td>train_test_model_6416e_00002</td><td>TERMINATED</td><td>127.0.0.1:8944 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">   0.226314</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.000162751</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        199.21  </td><td style=\"text-align: right;\">0.488112</td></tr>\n",
       "<tr><td>train_test_model_6416e_00003</td><td>TERMINATED</td><td>127.0.0.1:7236 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.360608</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.000138747</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        135.343 </td><td style=\"text-align: right;\">0.332226</td></tr>\n",
       "<tr><td>train_test_model_6416e_00004</td><td>TERMINATED</td><td>127.0.0.1:20616</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.358511</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00539041 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         46.4711</td><td style=\"text-align: right;\">0.686584</td></tr>\n",
       "<tr><td>train_test_model_6416e_00005</td><td>TERMINATED</td><td>127.0.0.1:27548</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">   0.243494</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000148946</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         49.2864</td><td style=\"text-align: right;\">0.109903</td></tr>\n",
       "<tr><td>train_test_model_6416e_00006</td><td>TERMINATED</td><td>127.0.0.1:14420</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">   0.228831</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.000513326</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        199.701 </td><td style=\"text-align: right;\">0.684061</td></tr>\n",
       "<tr><td>train_test_model_6416e_00007</td><td>TERMINATED</td><td>127.0.0.1:16876</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.182869</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.0119116  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        135.243 </td><td style=\"text-align: right;\">0.69356 </td></tr>\n",
       "<tr><td>train_test_model_6416e_00008</td><td>TERMINATED</td><td>127.0.0.1:22940</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.211087</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.0119396  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        137.953 </td><td style=\"text-align: right;\">0.734706</td></tr>\n",
       "<tr><td>train_test_model_6416e_00009</td><td>TERMINATED</td><td>127.0.0.1:11444</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">   0.153184</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000140712</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         46.5272</td><td style=\"text-align: right;\">0.03503 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_test_model pid=25400)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 1 loss: 1.0995271982493737\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 2 loss: 1.09783418297273\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 3 loss: 1.0961517219226884\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 4 loss: 1.0922066205764707\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 5 loss: 1.0730211759503947\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 6 loss: 0.7651785503284565\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 7 loss: 0.40689140174893423\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 8 loss: 0.2669117600498605\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 9 loss: 0.2162682832183927\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 10 loss: 0.19040049338149084\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 11 loss: 0.174125698731277\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 12 loss: 0.16124373499721412\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 13 loss: 0.14143810546821703\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 14 loss: 0.1330700199007679\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 15 loss: 0.1252808543269936\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 16 loss: 0.11013504114249312\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 17 loss: 0.10432769109676611\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 18 loss: 0.09228182494006587\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 19 loss: 0.08536992888681251\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 20 loss: 0.07156690126729363\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 21 loss: 0.07780644966915436\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 22 loss: 0.05579151495850618\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 23 loss: 0.051162970373580904\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 24 loss: 0.0525621722154783\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 25 loss: 0.04317879988096995\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 26 loss: 0.03866338513016747\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 27 loss: 0.03755621572171968\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 28 loss: 0.03299560814591596\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 29 loss: 0.026513434141532313\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 30 loss: 0.027491832454882067\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 1 loss: 1.0986059593553303\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 2 loss: 1.096531692172299\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 3 loss: 1.0925195898328508\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 4 loss: 1.0720820507081616\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 5 loss: 0.7665932601740381\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 6 loss: 0.394137876311771\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 7 loss: 0.2603458446771407\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 8 loss: 0.22227118143952695\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 9 loss: 0.1988434211405761\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 10 loss: 0.17388509503495292\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 11 loss: 0.15302443106369185\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 12 loss: 0.14201161603466803\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 13 loss: 0.1324878424061697\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 14 loss: 0.11617777617491719\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 15 loss: 0.10842445688009136\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 16 loss: 0.09794843924709228\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 17 loss: 0.09015888537910274\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 18 loss: 0.08249408592266508\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 19 loss: 0.0793777361899583\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 20 loss: 0.06964980376915646\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 21 loss: 0.05402049294696385\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 22 loss: 0.052408737078614286\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 23 loss: 0.04989125202175136\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 24 loss: 0.04450912499641843\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 25 loss: 0.04351303173168445\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 26 loss: 0.03135549437113795\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 27 loss: 0.029786298576323707\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 28 loss: 0.022359426114502746\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 29 loss: 0.028776447778321144\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 30 loss: 0.019360796639161622\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 1 loss: 1.0986001575986544\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 2 loss: 1.0975951567292213\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 3 loss: 1.0957127824425696\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 4 loss: 1.0909718424081802\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 5 loss: 1.0631912067532538\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 6 loss: 0.7205371749897798\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 7 loss: 0.4151803395710886\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 8 loss: 0.26804223166157803\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 9 loss: 0.2249064783876141\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 10 loss: 0.187127769109793\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 11 loss: 0.17244516348388667\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 12 loss: 0.1524511628493201\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 13 loss: 0.13289149624761193\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 14 loss: 0.12234326146232585\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 15 loss: 0.11495040912996046\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 16 loss: 0.09411359123769217\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 17 loss: 0.08233019108884036\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 18 loss: 0.07378968711321553\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 19 loss: 0.06332985797780566\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 20 loss: 0.05469753064389806\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 21 loss: 0.056844415064551866\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 22 loss: 0.04093111931191137\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 23 loss: 0.04429670954317165\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 24 loss: 0.033501558137262084\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 25 loss: 0.026795826324087103\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 26 loss: 0.02464782414220584\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 27 loss: 0.022381241317877235\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 28 loss: 0.019952718304072428\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 29 loss: 0.027314797450405118\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m Epoch 30 loss: 0.017762229466946642\n",
      "\u001b[36m(train_test_model pid=25400)\u001b[0m fit shape: (873, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_test_model_6416e_00000</td><td style=\"text-align: right;\">0.714657</td></tr>\n",
       "<tr><td>train_test_model_6416e_00001</td><td style=\"text-align: right;\">0.633559</td></tr>\n",
       "<tr><td>train_test_model_6416e_00002</td><td style=\"text-align: right;\">0.488112</td></tr>\n",
       "<tr><td>train_test_model_6416e_00003</td><td style=\"text-align: right;\">0.332226</td></tr>\n",
       "<tr><td>train_test_model_6416e_00004</td><td style=\"text-align: right;\">0.686584</td></tr>\n",
       "<tr><td>train_test_model_6416e_00005</td><td style=\"text-align: right;\">0.109903</td></tr>\n",
       "<tr><td>train_test_model_6416e_00006</td><td style=\"text-align: right;\">0.684061</td></tr>\n",
       "<tr><td>train_test_model_6416e_00007</td><td style=\"text-align: right;\">0.69356 </td></tr>\n",
       "<tr><td>train_test_model_6416e_00008</td><td style=\"text-align: right;\">0.734706</td></tr>\n",
       "<tr><td>train_test_model_6416e_00009</td><td style=\"text-align: right;\">0.03503 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_test_model pid=25400)\u001b[0m F1: 0.7146574338764715\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 1 loss: 1.099288844963327\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 2 loss: 1.098522651739635\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 3 loss: 1.098282789293661\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 4 loss: 1.0979129664630811\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 5 loss: 1.097463988169595\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 6 loss: 1.0970385193330123\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 7 loss: 1.0964582292865421\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 8 loss: 1.0958863655066589\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 9 loss: 1.09510863618732\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 10 loss: 1.093947880000989\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 11 loss: 1.0926618674978676\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 12 loss: 1.0904051673857502\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 13 loss: 1.0869660872146796\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 14 loss: 1.0810294591539629\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 15 loss: 1.0687303740948562\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 16 loss: 1.0388829495402292\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 17 loss: 0.9443322289039485\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 18 loss: 0.729070519263319\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 19 loss: 0.5374949147839764\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 20 loss: 0.43898053306514295\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 21 loss: 0.36375211463676943\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 22 loss: 0.2890723913104208\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 23 loss: 0.260106742320219\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 24 loss: 0.23446587830225463\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 25 loss: 0.22100667278301667\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 26 loss: 0.2124270695296437\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 27 loss: 0.2045310425004029\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 28 loss: 0.19354855333342838\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 29 loss: 0.18646524813319884\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 30 loss: 0.18453478708832344\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 1 loss: 1.0986518529282898\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 2 loss: 1.0982904804854834\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 3 loss: 1.0980392989992094\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 4 loss: 1.0977771893268873\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 5 loss: 1.0974390722122513\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 6 loss: 1.097092379541958\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 7 loss: 1.096650147638401\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 8 loss: 1.0962837002858394\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 9 loss: 1.0956461690053219\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 10 loss: 1.0948393089430672\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 11 loss: 1.0938036026073104\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 12 loss: 1.0923086730372005\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 13 loss: 1.0898452942110912\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 14 loss: 1.0861565741170354\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 15 loss: 1.0801231720868278\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 16 loss: 1.0675588029773295\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 17 loss: 1.036549767526258\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 18 loss: 0.9411632997148177\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 19 loss: 0.7229462066868774\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 20 loss: 0.5713980727586425\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 21 loss: 0.5142404221686996\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 22 loss: 0.45054488503882867\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 23 loss: 0.3847108764433059\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 24 loss: 0.3294889962285006\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 25 loss: 0.29801770534460287\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 26 loss: 0.2704520070252298\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 27 loss: 0.25158131740862083\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 28 loss: 0.24216027150885397\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 29 loss: 0.23236654413973584\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 30 loss: 0.2207840338443257\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 1 loss: 1.09925107806921\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 2 loss: 1.0985358312726021\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 3 loss: 1.0980959802865982\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 4 loss: 1.0976893405119579\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 5 loss: 1.0972905188798905\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 6 loss: 1.0966997598608335\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 7 loss: 1.0960969517628352\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 8 loss: 1.0953656961520513\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 9 loss: 1.0942307685812314\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 10 loss: 1.0926756660143535\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 11 loss: 1.0907931332786878\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 12 loss: 1.087263251344363\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 13 loss: 1.0809748565157256\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 14 loss: 1.0681037614742914\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 15 loss: 1.0304041514794031\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 16 loss: 0.9014583917955558\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 17 loss: 0.6506110756347577\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 18 loss: 0.5353215750306844\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 19 loss: 0.4761066621169448\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 20 loss: 0.41801761500537393\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 21 loss: 0.34310252824798226\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 22 loss: 0.295262187315772\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 23 loss: 0.2754352475206057\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 24 loss: 0.2471821377829959\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 25 loss: 0.22866700574134788\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 26 loss: 0.22707399362698197\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 27 loss: 0.20724808482142787\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 28 loss: 0.19587603627393643\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 29 loss: 0.18825817808198433\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m Epoch 30 loss: 0.18729237872175872\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=14488)\u001b[0m F1: 0.6335589603350423\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 1 loss: 1.0989467998757896\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 2 loss: 1.0985109088826477\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 3 loss: 1.0981469297804773\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 4 loss: 1.0979474963488915\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 5 loss: 1.0977902867487357\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 6 loss: 1.0975087450747667\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 7 loss: 1.0973143560263132\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 8 loss: 1.0970763801539092\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 9 loss: 1.0967769093533275\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 10 loss: 1.096446627650518\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 11 loss: 1.0961832555003186\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 12 loss: 1.0957798191125956\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 13 loss: 1.0953960913345526\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 14 loss: 1.094921099447116\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 15 loss: 1.0944681241799192\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 16 loss: 1.0937643961293073\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 17 loss: 1.093009781787999\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 18 loss: 1.0920724522523366\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 19 loss: 1.0909489593565216\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 20 loss: 1.0893525451545398\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 21 loss: 1.0873213949539848\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 22 loss: 1.0844956099739709\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 23 loss: 1.081361499317454\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 24 loss: 1.076400998469705\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 25 loss: 1.0705371914562842\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 26 loss: 1.0599226494053093\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 27 loss: 1.0434276681717995\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 28 loss: 1.0158538579693475\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 29 loss: 0.9661634448158296\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 30 loss: 0.8828056845427549\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 1 loss: 1.0999035882849653\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 2 loss: 1.099032266801145\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 3 loss: 1.0985328272110273\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 4 loss: 1.0982114883030163\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 5 loss: 1.0979560365696914\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 6 loss: 1.0977933021152722\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 7 loss: 1.0975678916237934\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 8 loss: 1.0974035395794557\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 9 loss: 1.097180414350093\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 10 loss: 1.096964646287325\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 11 loss: 1.096660172738949\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 12 loss: 1.0963896092246561\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 13 loss: 1.0960672332459138\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 14 loss: 1.0956864955545473\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 15 loss: 1.0953331246596425\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 16 loss: 1.0947865320353949\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 17 loss: 1.0943866872987826\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 18 loss: 1.0937417685484685\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 19 loss: 1.0930456208581685\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 20 loss: 1.0920947391946776\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 21 loss: 1.0910163456652344\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 22 loss: 1.0895944743597208\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 23 loss: 1.087849948586536\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 24 loss: 1.08567301165156\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 25 loss: 1.0827852695429026\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 26 loss: 1.0787827908491887\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 27 loss: 1.0730823864455985\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 28 loss: 1.064506164618901\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 29 loss: 1.0505288810539646\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 30 loss: 1.0274759925463621\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 1 loss: 1.0995989823888885\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 2 loss: 1.099082450030492\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 3 loss: 1.0987556443582747\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 4 loss: 1.0985448912937108\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 5 loss: 1.098436198055371\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 6 loss: 1.0983341063736376\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 7 loss: 1.0982304858763183\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 8 loss: 1.0981174864201555\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 9 loss: 1.0979360043380355\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 10 loss: 1.0978006455495113\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 11 loss: 1.0976315622289892\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 12 loss: 1.097554223771384\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 13 loss: 1.0972989185369089\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 14 loss: 1.0970918691730698\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 15 loss: 1.0968609702363143\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 16 loss: 1.0966387103644193\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 17 loss: 1.0964578335369803\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 18 loss: 1.0961598610828216\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 19 loss: 1.0958918815863654\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 20 loss: 1.095611476201354\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 21 loss: 1.0951158510120527\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 22 loss: 1.0947264213900476\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 23 loss: 1.094219382720103\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 24 loss: 1.0935956809615293\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 25 loss: 1.0929409263029477\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 26 loss: 1.0920601209668377\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 27 loss: 1.091037194514822\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 28 loss: 1.0898045264106702\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 29 loss: 1.0881505612291722\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m Epoch 30 loss: 1.0860232386061444\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=8944)\u001b[0m F1: 0.48811182771753653\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 1 loss: 1.0999889497440385\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 2 loss: 1.0995968209262705\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 3 loss: 1.0992148169838047\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 4 loss: 1.0989898962598619\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 5 loss: 1.0987735487118797\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 6 loss: 1.098577521154\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 7 loss: 1.0984494483322524\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 8 loss: 1.098280523327871\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 9 loss: 1.098221905993228\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 10 loss: 1.098127447717912\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 11 loss: 1.0980183969394794\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 12 loss: 1.0979697051384636\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 13 loss: 1.0979003258265896\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 14 loss: 1.0978498483594523\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 15 loss: 1.0977443060934295\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 16 loss: 1.0975934860617294\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 17 loss: 1.0975946573795619\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 18 loss: 1.0975382070818382\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 19 loss: 1.097525650534887\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 20 loss: 1.0973924700155298\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 21 loss: 1.0973124053962993\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 22 loss: 1.0972001735600199\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 23 loss: 1.097110184396451\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 24 loss: 1.097044846328957\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 25 loss: 1.0969927157603854\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 26 loss: 1.0968523752639898\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 27 loss: 1.0967120545533682\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 28 loss: 1.0966443580215897\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 29 loss: 1.0966167158111002\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 30 loss: 1.0964172920250794\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 1 loss: 1.09918787349172\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 2 loss: 1.0988877851422094\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 3 loss: 1.0986604339936201\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 4 loss: 1.0985056517504845\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 5 loss: 1.0983373427591403\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 6 loss: 1.0981423489185942\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 7 loss: 1.0980950268376775\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 8 loss: 1.0979705943780786\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 9 loss: 1.0978813196430688\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 10 loss: 1.0978074704899508\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 11 loss: 1.097685554448296\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 12 loss: 1.0975533037626444\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 13 loss: 1.0974915653717618\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 14 loss: 1.0973221289009607\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 15 loss: 1.0972421695204342\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 16 loss: 1.0971247724124364\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 17 loss: 1.097048538572648\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 18 loss: 1.0969627404413302\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 19 loss: 1.0968455912686195\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 20 loss: 1.0966909292365323\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 21 loss: 1.096591718557502\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 22 loss: 1.096393769027806\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 23 loss: 1.0963191425099093\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 24 loss: 1.0962181021185482\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 25 loss: 1.096085044516235\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 26 loss: 1.0959326674958236\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 27 loss: 1.0957916980030156\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 28 loss: 1.0956017339930815\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 29 loss: 1.0954170026699035\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 30 loss: 1.0951899886131287\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 1 loss: 1.1003946572542191\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 2 loss: 1.0996316333611806\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 3 loss: 1.09923507720232\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 4 loss: 1.098812455435594\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 5 loss: 1.0985607052842776\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 6 loss: 1.0983395208915074\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 7 loss: 1.098137919108073\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 8 loss: 1.0980661431948344\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 9 loss: 1.0979104593396187\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 10 loss: 1.097787509361903\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 11 loss: 1.0976793373624483\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 12 loss: 1.0975062976280847\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 13 loss: 1.0974416747689246\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 14 loss: 1.0972395146886507\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 15 loss: 1.0970996419588726\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 16 loss: 1.0969858417908351\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 17 loss: 1.0967448100447654\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 18 loss: 1.0965595816572506\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 19 loss: 1.0964797720313073\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 20 loss: 1.0963153744737306\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 21 loss: 1.0960126395026843\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 22 loss: 1.0958691348632177\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 23 loss: 1.0956367328763008\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 24 loss: 1.0955031534036002\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 25 loss: 1.0951790591080983\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 26 loss: 1.0949423119425774\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 27 loss: 1.0946580618619919\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 28 loss: 1.0944396018981934\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 29 loss: 1.0940475543340047\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m Epoch 30 loss: 1.0937318955858548\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=7236)\u001b[0m F1: 0.3322256752665714\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 1 loss: 1.0979709214689326\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 2 loss: 1.0861737925976638\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 3 loss: 0.6805317074184101\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 4 loss: 0.2336139851926026\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 5 loss: 0.1857099045856365\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 6 loss: 0.15006536907705775\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 7 loss: 0.12333664203186315\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 8 loss: 0.11351177664048567\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 9 loss: 0.09521962732416712\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 10 loss: 0.07665330314374996\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 1 loss: 1.0982944309210576\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 2 loss: 1.0847308410315954\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 3 loss: 0.6165808253303295\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 4 loss: 0.24531039475862468\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 5 loss: 0.20136559352341318\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 6 loss: 0.1572762796999652\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 7 loss: 0.13920566031098866\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 8 loss: 0.12494613216532503\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 9 loss: 0.097904670382889\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 10 loss: 0.08024636609675441\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 1 loss: 1.09931637297074\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 2 loss: 1.0887230023741723\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 3 loss: 0.7108105732128024\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 4 loss: 0.2841202810329075\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 5 loss: 0.19930297603229216\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 6 loss: 0.15760004842886702\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 7 loss: 0.12676656305557116\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 8 loss: 0.0950386659266466\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 9 loss: 0.08369739542346603\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m Epoch 10 loss: 0.06635610067266194\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=20616)\u001b[0m F1: 0.6865838886879422\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 1 loss: 1.1030659942153078\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 2 loss: 1.1021227977290657\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 3 loss: 1.1012755580570386\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 4 loss: 1.10063682357717\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 5 loss: 1.1001156879507976\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 6 loss: 1.0996673247828987\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 7 loss: 1.0991973573376674\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 8 loss: 1.0989400370520834\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 9 loss: 1.0986642682034036\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 10 loss: 1.098414084926155\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 1 loss: 1.0990807177885524\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 2 loss: 1.0989749326645952\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 3 loss: 1.0988824494979665\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 4 loss: 1.0987964411201716\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 5 loss: 1.0987585910461233\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 6 loss: 1.0986857616676475\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 7 loss: 1.0986786683400471\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 8 loss: 1.098582885550253\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 9 loss: 1.0985423918790038\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 10 loss: 1.0984570770143713\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 1 loss: 1.0990479752421378\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 2 loss: 1.0988641522824765\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 3 loss: 1.098781380802393\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 4 loss: 1.0986203640699386\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 5 loss: 1.0986222162842751\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 6 loss: 1.0985230669379233\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 7 loss: 1.0984198927879334\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 8 loss: 1.0982950359582901\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 9 loss: 1.0981984183192253\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m Epoch 10 loss: 1.0982050962746144\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=27548)\u001b[0m F1: 0.1099034058464556\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 1 loss: 1.0992085866908314\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 2 loss: 1.098477604725549\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 3 loss: 1.0980283061498428\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 4 loss: 1.0976865264390019\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 5 loss: 1.0971551399013313\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 6 loss: 1.096483702481535\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 7 loss: 1.0956292184556669\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 8 loss: 1.0942290642944115\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 9 loss: 1.091667894753183\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 10 loss: 1.087027345950178\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 11 loss: 1.0773600597104591\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 12 loss: 1.0477185421217527\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 13 loss: 0.9034071366816635\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 14 loss: 0.6020398061428822\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 15 loss: 0.46999650148682576\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 16 loss: 0.374719512691389\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 17 loss: 0.2946418303207985\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 18 loss: 0.24975988380533654\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 19 loss: 0.22474303084939595\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 20 loss: 0.20104049310026328\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 21 loss: 0.1898291593734407\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 22 loss: 0.18059854725804722\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 23 loss: 0.17382432690665078\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 24 loss: 0.16397181902992775\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 25 loss: 0.15848289119442963\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 26 loss: 0.15076658410054952\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 27 loss: 0.14593507433542016\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 28 loss: 0.1373837594738949\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 29 loss: 0.12851857484213977\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 30 loss: 0.1266261363185602\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 1 loss: 1.0991269795834517\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 2 loss: 1.097920441827854\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 3 loss: 1.0970762697588496\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 4 loss: 1.0961107559063856\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 5 loss: 1.0945506100895024\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 6 loss: 1.0920968551595671\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 7 loss: 1.0872392867292677\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 8 loss: 1.0757307305055506\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 9 loss: 1.0311876308767736\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 10 loss: 0.8167456419778472\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 11 loss: 0.5327322678405697\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 12 loss: 0.41940387814235286\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 13 loss: 0.34493967032983525\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 14 loss: 0.28875546396843027\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 15 loss: 0.2561678492401515\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 16 loss: 0.23121689921714553\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 17 loss: 0.22026117605806775\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 18 loss: 0.2122950212513449\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 19 loss: 0.20106855247897573\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 20 loss: 0.19144952808068516\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 21 loss: 0.18412569633434614\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 22 loss: 0.17629682229432678\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 23 loss: 0.17153824064019724\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 24 loss: 0.15726054640009435\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 25 loss: 0.15262601103539727\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 26 loss: 0.14312041495406233\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 27 loss: 0.13424758223754144\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 28 loss: 0.13028521592114434\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 29 loss: 0.12059304190842639\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 30 loss: 0.11283697524037556\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 1 loss: 1.0999057163525225\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 2 loss: 1.0983008156240857\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 3 loss: 1.097435631433459\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 4 loss: 1.0967176946070598\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 5 loss: 1.0953515317594333\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 6 loss: 1.0931497640550012\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 7 loss: 1.0894302682239476\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 8 loss: 1.080738502653755\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 9 loss: 1.0528342772376313\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 10 loss: 0.9069728808388083\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 11 loss: 0.6296787971867898\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 12 loss: 0.523759070107235\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 13 loss: 0.4316877706252458\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 14 loss: 0.3437318882024176\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 15 loss: 0.28471295474318786\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 16 loss: 0.24794554963147963\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 17 loss: 0.22517937938595242\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 18 loss: 0.2104993164500451\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 19 loss: 0.20595634072855706\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 20 loss: 0.1849910689222321\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 21 loss: 0.18340781265344774\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 22 loss: 0.17076415621378072\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 23 loss: 0.16284469929125184\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 24 loss: 0.1580908101942538\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 25 loss: 0.14974400080791003\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 26 loss: 0.140119038296704\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 27 loss: 0.134630188160957\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 28 loss: 0.12649957834604916\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 29 loss: 0.12197823344539299\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m Epoch 30 loss: 0.11804747123257617\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=14420)\u001b[0m F1: 0.6840611396341618\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 1 loss: 1.0975199571783611\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 2 loss: 0.624139872228889\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 3 loss: 0.2148010498569714\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 4 loss: 0.1382951999635772\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 5 loss: 0.10949891096336528\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 6 loss: 0.09076305544506218\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 7 loss: 0.08007160996674285\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 8 loss: 0.0681382426021126\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 9 loss: 0.06292125236395654\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 10 loss: 0.05078381845113846\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 11 loss: 0.041455830235074806\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 12 loss: 0.050678148966415926\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 13 loss: 0.03378369473730005\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 14 loss: 0.029643206133594623\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 15 loss: 0.024652253068493016\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 16 loss: 0.02335410678600535\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 17 loss: 0.022201244512248516\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 18 loss: 0.012891707149716105\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 19 loss: 0.012423637114871362\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 20 loss: 0.021983267630275805\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 21 loss: 0.01352557297032526\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 22 loss: 0.015418833653617426\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 23 loss: 0.014534373057845431\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 24 loss: 0.010788969832180981\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 25 loss: 0.013395874038106133\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 26 loss: 0.010620032524800621\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 27 loss: 0.005785200107968186\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 28 loss: 0.00686487261401185\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 29 loss: 0.016413587201831854\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 30 loss: 0.006718298898979723\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 1 loss: 1.0889686158224314\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 2 loss: 0.43409991992183594\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 3 loss: 0.2012100740406318\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 4 loss: 0.1512111846744983\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 5 loss: 0.12429930087562431\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 6 loss: 0.10362878758871161\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 7 loss: 0.08449939186117385\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 8 loss: 0.0764364708985883\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 9 loss: 0.06930627681788433\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 10 loss: 0.055593646631356984\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 11 loss: 0.0661695799641135\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 12 loss: 0.04596151278132647\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 13 loss: 0.041959596687645116\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 14 loss: 0.04604909407706665\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 15 loss: 0.03690627727869354\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 16 loss: 0.03372362998907039\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 17 loss: 0.025065915368092852\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 18 loss: 0.03328378839032361\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 19 loss: 0.014323162002408997\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 20 loss: 0.023405546065727582\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 21 loss: 0.019242733514307903\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 22 loss: 0.02491585369242777\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 23 loss: 0.01595661904759575\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 24 loss: 0.013712072521184\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 25 loss: 0.015602164267943981\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 26 loss: 0.01242743520530336\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 27 loss: 0.012510794725673475\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 28 loss: 0.006332641195115707\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 29 loss: 0.010547202009704297\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 30 loss: 0.006653951477094496\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 1 loss: 1.0952183544635772\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 2 loss: 0.5864688212537051\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 3 loss: 0.21232654319610447\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 4 loss: 0.1620542433714339\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 5 loss: 0.12136890359300499\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 6 loss: 0.09778994021811134\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 7 loss: 0.08574950706485349\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 8 loss: 0.08097602678559876\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 9 loss: 0.06923392996153173\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 10 loss: 0.04673809114798739\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 11 loss: 0.045278895996913586\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 12 loss: 0.03763376016698506\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 13 loss: 0.042183899649088134\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 14 loss: 0.03319870716707859\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 15 loss: 0.04414909732028415\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 16 loss: 0.02115935609611649\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 17 loss: 0.0274049251739901\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 18 loss: 0.023662206557613294\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 19 loss: 0.030281603205533733\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 20 loss: 0.018089044234663256\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 21 loss: 0.01126486548428905\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 22 loss: 0.012413913113141462\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 23 loss: 0.010388845783237717\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 24 loss: 0.007495578159752843\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 25 loss: 0.01030767775186329\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 26 loss: 0.01465023179160454\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 27 loss: 0.017873310453910562\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 28 loss: 0.010195368972256346\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 29 loss: 0.014821555755762954\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m Epoch 30 loss: 0.00729373647666686\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=16876)\u001b[0m F1: 0.6935599278875791\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 1 loss: 1.095201696597689\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 2 loss: 0.5399464835949953\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 3 loss: 0.19590870308770925\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 4 loss: 0.14283155910748047\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 5 loss: 0.10865911661117836\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 6 loss: 0.09861677296312828\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 7 loss: 0.08049604923491409\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 8 loss: 0.06376658100634813\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 9 loss: 0.05104431646457715\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 10 loss: 0.043465126282632105\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 11 loss: 0.04073860258730109\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 12 loss: 0.040450936416707474\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 13 loss: 0.03680703306004996\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 14 loss: 0.034356430021845984\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 15 loss: 0.01657404398924335\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 16 loss: 0.02930204110709526\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 17 loss: 0.02443387842708095\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 18 loss: 0.01597745807162009\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 19 loss: 0.017805542249190988\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 20 loss: 0.008988965079324809\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 21 loss: 0.005839403854836018\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 22 loss: 0.02347920179717036\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 23 loss: 0.011411024861747093\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 24 loss: 0.01419818730122401\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 25 loss: 0.0104116259947063\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 26 loss: 0.003584986527560458\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 27 loss: 0.00987191908653393\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 28 loss: 0.013170973812290765\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 29 loss: 0.010650654525679558\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 30 loss: 0.010269711920398519\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 1 loss: 1.0957954505912395\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 2 loss: 0.5670279177735332\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 3 loss: 0.21887014483046882\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 4 loss: 0.15066632725486234\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 5 loss: 0.12234372203825276\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 6 loss: 0.09487453269764405\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 7 loss: 0.08135504831125599\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 8 loss: 0.06542760668128744\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 9 loss: 0.06306509644247028\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 10 loss: 0.05404602048895126\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 11 loss: 0.057791025758360925\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 12 loss: 0.05398788463036694\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 13 loss: 0.039991789181083794\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 14 loss: 0.04070110769490927\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 15 loss: 0.04538475175118152\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 16 loss: 0.01718588772231318\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 17 loss: 0.026583838137710456\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 18 loss: 0.027854515396732595\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 19 loss: 0.01803117895261272\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 20 loss: 0.019300468748806757\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 21 loss: 0.01336463370336344\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 22 loss: 0.01740847731645711\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 23 loss: 0.018704824385526952\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 24 loss: 0.009132065429670195\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 25 loss: 0.013287230415859512\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 26 loss: 0.011755961615586065\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 27 loss: 0.007699097110397273\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 28 loss: 0.012321557292650805\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 29 loss: 0.015781082636734202\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 30 loss: 0.010196574539781787\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 1 loss: 1.0868845137457053\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 2 loss: 0.48695706349487106\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 3 loss: 0.19471078092077126\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 4 loss: 0.14206501668474328\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 5 loss: 0.1076108581823064\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 6 loss: 0.10204775797901675\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 7 loss: 0.06714203719942209\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 8 loss: 0.058560699194155554\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 9 loss: 0.048618542985301855\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 10 loss: 0.06468467470646526\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 11 loss: 0.04431912040320943\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 12 loss: 0.03089785597780974\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 13 loss: 0.03877045882969412\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 14 loss: 0.02358001286830813\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 15 loss: 0.022867519604066425\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 16 loss: 0.02143144099847518\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 17 loss: 0.020521853792827945\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 18 loss: 0.017914547253856956\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 19 loss: 0.01676615719552501\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 20 loss: 0.012790770554549032\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 21 loss: 0.020022401137475755\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 22 loss: 0.01176308130070538\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 23 loss: 0.008210511137788975\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 24 loss: 0.010090165897069407\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 25 loss: 0.007830900931078707\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 26 loss: 0.006441816290161265\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 27 loss: 0.009931937886252247\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 28 loss: 0.006124810075765197\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 29 loss: 0.010005503262918106\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m Epoch 30 loss: 0.003545764485052875\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=22940)\u001b[0m F1: 0.7347055704682596\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m (1746, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 1 loss: 1.0995989177236913\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 2 loss: 1.0993324661650599\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 3 loss: 1.0991500893074446\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 4 loss: 1.0989929363440676\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 5 loss: 1.098874627307243\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 6 loss: 1.098803358948577\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 7 loss: 1.098754137383457\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 8 loss: 1.098625215257352\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 9 loss: 1.098561247354721\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 10 loss: 1.0985140290992388\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m fit shape: (874, 256)\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 1 loss: 1.1011771234143681\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 2 loss: 1.1005020597401787\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 3 loss: 1.1000304312265219\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 4 loss: 1.0995984067436027\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 5 loss: 1.0992585550837155\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 6 loss: 1.0989675076067948\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 7 loss: 1.0987914470063538\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 8 loss: 1.0985880368897896\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 9 loss: 1.0984158666193986\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 10 loss: 1.0983268348108821\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m fit shape: (873, 256)\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m start\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m (1747, 3, 16, 16)\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 1 loss: 1.098975960413615\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 2 loss: 1.0990066965421041\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 3 loss: 1.0988659794131914\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 4 loss: 1.0987650061647096\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 5 loss: 1.098496919373671\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 6 loss: 1.0984584117929141\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 7 loss: 1.09842669069767\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 8 loss: 1.0983416820565859\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 9 loss: 1.098293562233448\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m Epoch 10 loss: 1.098192805548509\n",
      "\u001b[36m(train_test_model pid=11444)\u001b[0m fit shape: (873, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 18:50:08,993\tINFO tune.py:1047 -- Total run time: 1364.04 seconds (1363.97 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_test_model pid=11444)\u001b[0m F1: 0.035030041942306286\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If set, `mode` has to be one of [min, max]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ian\\OneDrive - National University of Singapore\\Y2S1\\CS2109S\\Finals\\final\\tuning.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m# \"criterion\": tune.choice([nn.CrossEntropyLoss, nn.MSELoss]),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m# \"scaler\": tune.choice([MinMaxScaler(), StandardScaler()]),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         \u001b[39m# \"class_weights\": tune.grid_search(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         \u001b[39m#         )\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m analysis \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     train_test_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m best_trial \u001b[39m=\u001b[39m analysis\u001b[39m.\u001b[39;49mget_best_trial(\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mavg\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mlast\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/OneDrive%20-%20National%20University%20of%20Singapore/Y2S1/CS2109S/Finals/final/tuning.ipynb#Y260sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mprint\u001b[39m(best_trial\u001b[39m.\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\Ian\\miniconda3\\envs\\cs2109s-2310-final\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:535\u001b[0m, in \u001b[0;36mExperimentAnalysis.get_best_trial\u001b[1;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials[\u001b[39m0\u001b[39m]\n\u001b[0;32m    534\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_metric(metric)\n\u001b[1;32m--> 535\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_mode(mode)\n\u001b[0;32m    537\u001b[0m \u001b[39mif\u001b[39;00m scope \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast-5-avg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast-10-avg\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    538\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    539\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExperimentAnalysis: attempting to get best trial for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmetric \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for scope \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not in [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         )\n\u001b[0;32m    546\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ian\\miniconda3\\envs\\cs2109s-2310-final\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:650\u001b[0m, in \u001b[0;36mExperimentAnalysis._validate_mode\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    646\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo `mode` has been passed and  `default_mode` has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    647\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot been set. Please specify the `mode` parameter.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    648\u001b[0m     )\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39mand\u001b[39;00m mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 650\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf set, `mode` has to be one of [min, max]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    651\u001b[0m \u001b[39mreturn\u001b[39;00m mode \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_mode\n",
      "\u001b[1;31mValueError\u001b[0m: If set, `mode` has to be one of [min, max]"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from ray import train\n",
    "from ray.air import session\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def drop_nan_y(X, y):\n",
    "    nan_indices = np.argwhere(np.isnan(y)).squeeze()\n",
    "    mask = np.ones(y.shape, bool)\n",
    "    mask[nan_indices] = False\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    return X, y\n",
    "\n",
    "# Load data\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']\n",
    "\n",
    "\n",
    "X, y = drop_nan_y(X, y)\n",
    "\n",
    "def train_test_model(config):\n",
    "    model = Model(\n",
    "        batch_size=config[\"batch_size\"],\n",
    "                    epochs=config[\"epochs\"], \n",
    "                    # criterion=config[\"criterion\"],\n",
    "                    # scaler=config[\"scaler\"],\n",
    "                    learning_rate=config[\"lr\"])\n",
    "                    # class_weights=config[\"class_weights\"],\n",
    "                    \n",
    "    \n",
    "    kf = KFold(n_splits=3)\n",
    "    f1_scores = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, predictions, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    print(\"F1:\", avg_f1)\n",
    "    train.report({\"score\": avg_f1})\n",
    "    \n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"drop_prob\": tune.uniform(0.1, 0.5),\n",
    "    \"batch_size\": tune.choice([10, 20, 30]),\n",
    "    \"epochs\": tune.choice([10, 20, 30]),\n",
    "}\n",
    "    # \"criterion\": tune.choice([nn.CrossEntropyLoss, nn.MSELoss]),\n",
    "    # \"scaler\": tune.choice([MinMaxScaler(), StandardScaler()]),\n",
    "        # \"class_weights\": tune.grid_search(\n",
    "        #     map(lambda x: torch.tensor(x, dtype=torch.float32),\n",
    "        #         [[1.0, 3.0, 5.0],\n",
    "        #           [1.0, 5.0, 10.0],\n",
    "        #             [1.0, 10.0, 35.0],\n",
    "        #             [1.0, 10.0, 50.0],\n",
    "        #               [1.0, 100.0, 500.0]]\n",
    "        #         )\n",
    "        #     )\n",
    "\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_test_model,\n",
    "    config=config,\n",
    "    num_samples=10, \n",
    "    resources_per_trial={\"cpu\": 16, \"gpu\": 1} \n",
    "\n",
    ")\n",
    "best_trial = analysis.get_best_trial(\"score\",\"avg\",\"last\")\n",
    "print(best_trial.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6df97cb7432b9",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "2023-11-26 13:26:34,995\tINFO tune.py:1047 -- Total run time: 583.14 seconds (583.05 seconds for the tuning loop).\n",
    "{'lr': 0.0003826645125269827, 'drop_prob': 0.23535222860200122, 'batch_size': 20, 'epochs': 10, 'scaler': StandardScaler()}\n",
    "\n",
    "\n",
    "Trial name\t                    status\tloc\t       batch_size\tdrop_prob\tepochs\tlr\titer\ttotal time (s)\tscore\n",
    "\n",
    "train_test_model_6416e_00008\tTERMINATED\t127.0.0.1:22940\t20\t0.211087\t30\t0.0119396\t1\t137.953\t0.734706\n",
    "\n",
    "train_test_model_6416e_00008\tTERMINATED\t127.0.0.1:22940\t20\t0.211087\t30\t0.0119396\t1\t137.953\t0.734706\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
